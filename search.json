[
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A collection of my projects and experiences\n\n\n\n\n\n\n\n\n\n\nFundamentals of Backpropogation (WIP)\n\n\nBuilding a prerequiste to a fundamental technique.\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 3, 2024\n\n\nHaliq\n\n\n\n\n\n\n\n\n\n\n\n\nASCII Rendering (WIP)\n\n\nInspired by a video by Acerola, to do visualized image rendering or shader.\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\nHaliq\n\n\n\n\n\n\n\n\n\n\n\n\nProcedural Animation (WIP)\n\n\nLearning procedural techniques and mathematics.\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nJul 22, 2024\n\n\nHaliq\n\n\n\n\n\n\n\n\n\n\n\n\nDigit Recognizer with CNN (MNIST)\n\n\nA beginner’s exploration into Convolutional Neural Networks (CNNs)\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\nHaliq\n\n\n\n\n\n\n\n\n\n\n\n\nKorean Language Learning\n\n\nLingustics is a interesting topic.\n\n\n\nLanguage\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\nHaliq\n\n\n\n\n\n\n\n\n\n\n\n\nConway’s Game of life (WIP)\n\n\nRecreating chaotic systems using Java.\n\n\n\nCode\n\n\n\n\n\n\n\n\n\nSep 20, 2021\n\n\nHaliq\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/kr.html",
    "href": "posts/kr.html",
    "title": "Korean Language Learning",
    "section": "",
    "text": "Some where in 2021, I started getting interested in Linguistics. As part of this interest, I started learning Korean. It was a very interesting language to learn. And surprisingly, Korean is a very easy language to learn “TO READ”. The specific grammars and sentences structures are very complex in contrast.\nA simple resource to learn Korean is through the use of the following website: Talk to me in Korean This website provides a very good resource to learn Korean. It provides a structured learning path for beginners to advanced learners.\nAnother resource that I found useful is the use of Anki. Anki is a flashcard app that uses spaced repetition to help you remember words and phrases. It is a very useful tool to help you remember vocabulary and grammar rules. It makes use of the concept of spaced repetition to help you remember words and phrases more effectively by showing you the flashcards at increasing intervals of time which helps you remember them better.\nRefold is another resource that I found useful. Refold is a community of language learners who share their experiences and techniques for learning languages. They have a structured learning path that helps you learn languages more effectively. They also have a forum where you can ask questions and get help from other learners. The main idea behind Refold is in immersion and learning through context, rather than through traditional methods like memorization. This is a very effective way to learn languages as it helps you learn the language in a more natural way.\nAlong the way, I’ve learnt many techniques and pedagogies to learn not only languages better but also to build better understanding and retention of learning new skills and knowledge. Such as the use of spaced repetition, active recall and the use of mnemonics.\nLately however I haven’t gotten the chance to continue learning Korean and I haven’t been able to practice it as much as I would like. I believe that learning a new language is a very rewarding experience and it opens up new opportunities, friends and perspectives."
  },
  {
    "objectID": "posts/digi.html",
    "href": "posts/digi.html",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "",
    "text": "One of the most common projects for begginers to learn about Convolutional Neural Networks (CNNs) is the MNIST dataset. The MNIST dataset is a collection of 28x28 pixel grayscale images of handwritten digits (0-9). The goal of this project is to build a CNN model that can accurately classify these handwritten digits. It is one of the most popular datasets available on Kaggle and is often used as a learning tool for beginners in the field of deep learning.\nIn this project, we will learn about CNNs, how they work, and how to build a simple but effective CNN model using TensorFlow and Keras. We will also explore techniques such as data preprocessing, model training, and evaluation."
  },
  {
    "objectID": "posts/digi.html#project-introduction",
    "href": "posts/digi.html#project-introduction",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "",
    "text": "One of the most common projects for begginers to learn about Convolutional Neural Networks (CNNs) is the MNIST dataset. The MNIST dataset is a collection of 28x28 pixel grayscale images of handwritten digits (0-9). The goal of this project is to build a CNN model that can accurately classify these handwritten digits. It is one of the most popular datasets available on Kaggle and is often used as a learning tool for beginners in the field of deep learning.\nIn this project, we will learn about CNNs, how they work, and how to build a simple but effective CNN model using TensorFlow and Keras. We will also explore techniques such as data preprocessing, model training, and evaluation."
  },
  {
    "objectID": "posts/digi.html#dataset-overview",
    "href": "posts/digi.html#dataset-overview",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "Dataset Overview",
    "text": "Dataset Overview\nThe MNIST dataset consists of 60,000 training images and 10,000 test images. Each image is a 28x28 pixel grayscale image of a handwritten digit (0-9). The dataset is divided into 10 classes, one for each digit. The goal is to build a model that can accurately classify these images into their respective classes.\nAnother common method to expand our dataset is through data augmentation. Data augmentation is a technique used to artificially increase the size of the training dataset by applying random transformations to the images. This helps the model generalize better and improve its performance on unseen data. In this scenario, we apply basic transformations such as stretching the images without fundamentally changing the content."
  },
  {
    "objectID": "posts/digi.html#understanding-convolutional-models",
    "href": "posts/digi.html#understanding-convolutional-models",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "Understanding Convolutional Models",
    "text": "Understanding Convolutional Models\nOne of the key challenges of this dataset is the simplicity of the images. The digits are handwritten and can vary in style and quality. This makes it a good dataset for beginners to learn about image classification and CNNs.\nThe most common structure of a CNN model consists of convolutional layers, pooling layers, and fully connected layers. Convolutional layers are used to extract features from the input image, while pooling layers are used to reduce the spatial dimensions of the feature maps. Fully connected layers are used to make predictions based on the extracted features.\nTo be more detailed, a convolutional layer is similar to a sliding window that moves across the input image. Through this sliding windows, a matrix calculation is done with a filter (also known as a kernel). This results in a feature map that highlight small patterns in the image. We the extract these smaller patterns and slowly pass them through the network to create larger patterns. We do this process iteratively to create a more complex model.\nA more intuitive way to understand this can be seen in the following video:"
  },
  {
    "objectID": "posts/digi.html#convulutional-neural-network-model",
    "href": "posts/digi.html#convulutional-neural-network-model",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "Convulutional Neural Network Model",
    "text": "Convulutional Neural Network Model"
  },
  {
    "objectID": "posts/digi.html#the-following-code-is-a-simplified-version-of-the-cnn-model.-for-a-more-detailed-implementation-please-refer-to-the-full-code-on-colab-here",
    "href": "posts/digi.html#the-following-code-is-a-simplified-version-of-the-cnn-model.-for-a-more-detailed-implementation-please-refer-to-the-full-code-on-colab-here",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "The following code is a simplified version of the CNN model. For a more detailed implementation, please refer to the full code on colab here",
    "text": "The following code is a simplified version of the CNN model. For a more detailed implementation, please refer to the full code on colab here\n\n# CNN Model\n# CNN Architecture works by Convolutions, Pooling and then Flattening before the Fully Connected Layer.\n\nmodel = Sequential([\n\n# Convolutional Layer process\nlayers.Conv2D(32, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)),\n# Pooling acts as a downsampling filter. It reduces the dimensionality of each feature map but retains the most important information.\nlayers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n# Dropout is a regularization technique where we randomly set neurons in a layer to zero. This helps prevent overfitting and improve training.\nlayers.Dropout(0.2),\n# Batch Normalization normalizes the activations in the previous layer at each batch.\nlayers.BatchNormalization(),\n\n# We do this 3 times to increase the depth of the network. This allows the network to learn more complex features.\nlayers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\nlayers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\nlayers.Dropout(0.2),\nlayers.BatchNormalization(),\n\nlayers.Conv2D(64, kernel_size=3, padding='same', activation='relu'),\nlayers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\nlayers.Dropout(0.2),\nlayers.BatchNormalization(),\n\n# Flatten the output from the convolutional layers so that it can be input into the fully connected layer.\nlayers.Flatten(),\nlayers.Dense(512, activation='relu'),\nlayers.BatchNormalization(),\nlayers.Dropout(0.3),\nlayers.Dense(10, activation='softmax'),\n\n])"
  },
  {
    "objectID": "posts/digi.html#after-training",
    "href": "posts/digi.html#after-training",
    "title": "Digit Recognizer with CNN (MNIST)",
    "section": "After training",
    "text": "After training\nWe get the following results after training the models in the last 5 epochs:\n|Epoch 18/50 |460/460 - 1s - 2ms/step - accuracy: 1.0000 - loss: 0.0118 - val_accuracy: 0.9931 - val_loss: 0.0253 |Epoch 19/50 |460/460 - 16s - 34ms/step - accuracy: 0.9821 - loss: 0.0571 - val_accuracy: 0.9917 - val_loss: 0.0342 |Epoch 20/50 |460/460 - 1s - 1ms/step - accuracy: 0.9756 - loss: 0.0700 - val_accuracy: 0.9917 - val_loss: 0.0351 |Epoch 21/50 |460/460 - 16s - 34ms/step - accuracy: 0.9811 - loss: 0.0582 - val_accuracy: 0.9936 - val_loss: 0.0269 |Epoch 22/50 |460/460 - 1s - 1ms/step - accuracy: 0.9878 - loss: 0.0299 - val_accuracy: 0.9936 - val_loss: 0.0269\nThe model has an accuracy of 99.36% on the validation set after 22 epochs. This is a good result and shows that the model is performing well on the test data. We can show a simple list of the predictions and the actual inputs to see how well the model is performing."
  },
  {
    "objectID": "posts/ascii rendering.html",
    "href": "posts/ascii rendering.html",
    "title": "ASCII Rendering (WIP)",
    "section": "",
    "text": "| . | ; | o | ? | $ | #, luminance difference 0.10 &gt; Filter\n/  _ &gt; Guassian Blur, Sobel Filter,\nPooling from CNN, Edge Detection"
  },
  {
    "objectID": "Hobbies.html",
    "href": "Hobbies.html",
    "title": "My Hobbies",
    "section": "",
    "text": "Outside of technical projects, I spend most of my time pursuing Sport Climbing and bouldering as a fulfilling hobby to keep me active and healthy.\n\nSport climbing is an exhilarating form of rock climbing where climbers ascend pre-bolted routes using ropes and harnesses for protection. Requiring immense physical and mental strength, sport climbing tests climbers’ technique, endurance, and problem-solving skills as they navigate challenging overhangs, crimps, and dynamic movements on vertical rock faces."
  },
  {
    "objectID": "Hobbies.html#sport-climbing",
    "href": "Hobbies.html#sport-climbing",
    "title": "My Hobbies",
    "section": "",
    "text": "Outside of technical projects, I spend most of my time pursuing Sport Climbing and bouldering as a fulfilling hobby to keep me active and healthy.\n\nSport climbing is an exhilarating form of rock climbing where climbers ascend pre-bolted routes using ropes and harnesses for protection. Requiring immense physical and mental strength, sport climbing tests climbers’ technique, endurance, and problem-solving skills as they navigate challenging overhangs, crimps, and dynamic movements on vertical rock faces."
  },
  {
    "objectID": "Hobbies.html#classical-guitar",
    "href": "Hobbies.html#classical-guitar",
    "title": "My Hobbies",
    "section": "Classical Guitar",
    "text": "Classical Guitar\nI also enjoy practicing the classical guitar although I am not very good at it. I find it a relaxing activity."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Abdul Haliq",
    "section": "",
    "text": "Hello, I am a undergraduate AI Engineer at Singapore Institute of Technology. I enjoy exploring new technical projects, learning languages and bouldering/sport climbing."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Abdul Haliq",
    "section": "Education",
    "text": "Education\nSingapore Institure of Technology, Singapore | Bachelor of Science w/ Honours in Applied Artificial Intelligence | Sept 2024 - Apr 2026"
  },
  {
    "objectID": "posts/backpropogation.html",
    "href": "posts/backpropogation.html",
    "title": "Fundamentals of Backpropogation (WIP)",
    "section": "",
    "text": "One of the most fundamental techniques in Machine Learning is Backpropogation. From ML Models, Neural Networks and Convolutional Networks. An underlying principle for all these methods to function is the use of Backpropogation.\nIn my experience, I’ve learnt that a key understanding to Backpropogation can allow for a more accurate, fine-tuned solutions to data models. Allowing us to build and debug better when constructing models. Which is why we will explore our understanding further to build a solid foundation."
  },
  {
    "objectID": "posts/backpropogation.html#inspired-by-artem-kisanov",
    "href": "posts/backpropogation.html#inspired-by-artem-kisanov",
    "title": "Fundamentals of Backpropogation (WIP)",
    "section": "Inspired by Artem Kisanov",
    "text": "Inspired by Artem Kisanov"
  },
  {
    "objectID": "posts/gol.html",
    "href": "posts/gol.html",
    "title": "Conway’s Game of life (WIP)",
    "section": "",
    "text": "An interesting study about chaotic systems that I decided to recreate using Java and LibGDX.\n\n\n\nExample\n\n\nConway’s Game of Life is a fascinating example of a simple set of rules that can give rise to complex and unpredictable behavior, highlighting the intricate connections between simple systems and chaos. Developed by mathematician John Conway in 1970, the Game of Life is a cellular automaton, a computational model that operates on a grid of cells, each of which can be in one of two states: alive or dead. The rules that govern the evolution of the Game of Life are deceptively simple: a living cell with two or three living neighbors survives to the next generation, a dead cell with exactly three living neighbors becomes alive, and all other cells either die or remain dead. Despite these straightforward rules, the Game of Life exhibits a remarkable range of behaviors, from stable patterns that remain unchanged indefinitely to oscillating patterns that cycle through a series of states, and even patterns that exhibit chaotic, unpredictable behavior.\nThe Game of Life’s ability to produce complex and seemingly chaotic patterns from such simple rules has profound implications for our understanding of chaotic systems in general, and for the field of artificial intelligence in particular. It demonstrates that even relatively simple systems can exhibit highly complex and unpredictable behavior, a concept that is central to many areas of machine learning and AI. Neural networks, for instance, are built on the principle of combining simple computational units in intricate ways to produce complex and intelligent behavior. Furthermore, the Game of Life has been used as a testbed for exploring various algorithms and techniques in AI, such as genetic algorithms and cellular automata-based computing. By studying how patterns evolve and interact in the Game of Life, researchers can gain insights into the behavior of complex systems and develop new strategies for solving challenging problems. Overall, Conway’s Game of Life serves as a powerful metaphor for the intricate relationships between simplicity and complexity, order and chaos, and the potential for complex and intelligent behavior to emerge from relatively simple systems."
  },
  {
    "objectID": "posts/gol.html#a-summary-of-conways-game-of-life",
    "href": "posts/gol.html#a-summary-of-conways-game-of-life",
    "title": "Conway’s Game of life (WIP)",
    "section": "",
    "text": "An interesting study about chaotic systems that I decided to recreate using Java and LibGDX.\n\n\n\nExample\n\n\nConway’s Game of Life is a fascinating example of a simple set of rules that can give rise to complex and unpredictable behavior, highlighting the intricate connections between simple systems and chaos. Developed by mathematician John Conway in 1970, the Game of Life is a cellular automaton, a computational model that operates on a grid of cells, each of which can be in one of two states: alive or dead. The rules that govern the evolution of the Game of Life are deceptively simple: a living cell with two or three living neighbors survives to the next generation, a dead cell with exactly three living neighbors becomes alive, and all other cells either die or remain dead. Despite these straightforward rules, the Game of Life exhibits a remarkable range of behaviors, from stable patterns that remain unchanged indefinitely to oscillating patterns that cycle through a series of states, and even patterns that exhibit chaotic, unpredictable behavior.\nThe Game of Life’s ability to produce complex and seemingly chaotic patterns from such simple rules has profound implications for our understanding of chaotic systems in general, and for the field of artificial intelligence in particular. It demonstrates that even relatively simple systems can exhibit highly complex and unpredictable behavior, a concept that is central to many areas of machine learning and AI. Neural networks, for instance, are built on the principle of combining simple computational units in intricate ways to produce complex and intelligent behavior. Furthermore, the Game of Life has been used as a testbed for exploring various algorithms and techniques in AI, such as genetic algorithms and cellular automata-based computing. By studying how patterns evolve and interact in the Game of Life, researchers can gain insights into the behavior of complex systems and develop new strategies for solving challenging problems. Overall, Conway’s Game of Life serves as a powerful metaphor for the intricate relationships between simplicity and complexity, order and chaos, and the potential for complex and intelligent behavior to emerge from relatively simple systems."
  }
]